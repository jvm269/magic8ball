{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Import mnist data-set, it's already a built in data set\n",
    "data = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data set is split into train and test data sets\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a total of 70 k images\n",
    "# 60k for training and 10k for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the images are 28x28 pixles --> our victors will be 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns:\n",
    "\n",
    "#2 tuples:\n",
    "#x_train, x_test: uint8 array of grayscale image data with shape (num_samples, 28, 28).\n",
    "#y_train, y_test: uint8 array of digit labels (integers in range 0-9) with shape (num_samples,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,784) # we not have matrixes of 28x28 we need to vectorize each digit into 784\n",
    "x_test = x_test.reshape(10000,784)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_layer_size = 784    # 28X28 Pixles\n",
    "hidden_layer_size = 25    # 25 hidden units\n",
    "num_labels = 10          # 10 labels, from 0 to 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to hot-encode Y-values each digit into 0s and 1s so it look in the form of 0000001010\n",
    "y_train = to_categorical(y_train, num_classes=num_labels)\n",
    "y_test = to_categorical(y_test, num_classes=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test hot encoder\n",
    "y_test[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0923 16:22:04.756889 4422993344 deprecation_wrapper.py:119] From /anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0923 16:22:04.784842 4422993344 deprecation_wrapper.py:119] From /anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0923 16:22:04.791411 4422993344 deprecation_wrapper.py:119] From /anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0923 16:22:04.806426 4422993344 deprecation_wrapper.py:119] From /anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0923 16:22:04.815227 4422993344 deprecation.py:506] From /anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create MLP model\n",
    "model = Sequential()     \n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))    #First hidden layer, 512 neurons, activation relu, input 784 array --num pixels--\n",
    "model.add(Dropout(0.2))                                         \n",
    "model.add(Dense(512, activation='relu'))                       \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_labels, activation='softmax'))   # Final layer, 10 outputs 1-10\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      " - 6s - loss: 11.2934 - acc: 0.2993 - val_loss: 11.2698 - val_acc: 0.3008\n",
      "Epoch 2/12\n",
      " - 5s - loss: 11.2916 - acc: 0.2994 - val_loss: 11.2719 - val_acc: 0.3006\n",
      "Epoch 3/12\n",
      " - 5s - loss: 11.2752 - acc: 0.3004 - val_loss: 11.1876 - val_acc: 0.3059\n",
      "Epoch 4/12\n",
      " - 5s - loss: 11.3096 - acc: 0.2983 - val_loss: 12.3451 - val_acc: 0.2340\n",
      "Epoch 5/12\n",
      " - 5s - loss: 11.7410 - acc: 0.2715 - val_loss: 11.1892 - val_acc: 0.3058\n",
      "Epoch 6/12\n",
      " - 5s - loss: 11.2754 - acc: 0.3005 - val_loss: 11.1860 - val_acc: 0.3060\n",
      "Epoch 7/12\n",
      " - 5s - loss: 11.3439 - acc: 0.2962 - val_loss: 12.7745 - val_acc: 0.2074\n",
      "Epoch 8/12\n",
      " - 6s - loss: 12.0031 - acc: 0.2553 - val_loss: 11.2472 - val_acc: 0.3022\n",
      "Epoch 9/12\n",
      " - 6s - loss: 11.7312 - acc: 0.2721 - val_loss: 11.6276 - val_acc: 0.2786\n",
      "Epoch 10/12\n",
      " - 6s - loss: 11.6365 - acc: 0.2780 - val_loss: 11.4680 - val_acc: 0.2885\n",
      "Epoch 11/12\n",
      " - 6s - loss: 11.6655 - acc: 0.2762 - val_loss: 11.9322 - val_acc: 0.2597\n",
      "Epoch 12/12\n",
      " - 6s - loss: 11.5324 - acc: 0.2845 - val_loss: 11.3342 - val_acc: 0.2968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb42275e48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit our model to the data set\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=12, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the weights and model in Json for flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_json\", \"w\") as json_file:\n",
    " json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
